import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


# --------------------
# 1) í˜ì´ì§€ & í—¤ë”
# --------------------
st.set_page_config(page_title='Machine Learning Report', page_icon='ğŸ’»')
st.sidebar.header('ğŸ“Š Machine Learning Report')
st.header('Machine Learning Report', divider='rainbow')

# --------------------
# 2) ë°ì´í„° ë¡œë“œ & ê¸°ë³¸ í™•ì¸
# --------------------
df = pd.read_csv('Obesity Classification.csv')
st.subheader('Raw Data Preview')
st.write(df.head())

# ê²°ì¸¡ì¹˜ í™•ì¸
st.subheader('Missing Values')
missing = df.isnull().sum()
st.write(missing)

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
num_cols = ['Age', 'Height', 'Weight', 'BMI']
imp_mean = SimpleImputer(strategy='mean')
df[num_cols] = imp_mean.fit_transform(df[num_cols])

# ë²”ì£¼í˜• ê²°ì¸¡(ì„±ë³„)ì— ëŒ€í•œ ìµœë¹ˆê°’ ëŒ€ì²´
if df['Gender'].isnull().any():
    imp_freq = SimpleImputer(strategy='most_frequent')
    df[['gender']] = imp_freq.fit_transform(df[['Gender']])

# ì´ìƒì¹˜ ì²˜ë¦¬(IQR)
def cap_outlier(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR
    return series.clip(lower, upper)
for col in num_cols:
    df[col] = cap_outlier(df[col])


# --------------------
# 5) ë ˆì´ë¸” ì¸ì½”ë”© & ìŠ¤ì¼€ì¼ë§
# --------------------
le = LabelEncoder()
df['Gender'] = le.fit_transform(df['Gender'])
df['Label_enc'] = le.fit_transform(df['Label'])  # ì˜ˆì¸¡ ëŒ€ìƒë„ ì¸ì½”ë”©

scaler = StandardScaler()
df[num_cols] = scaler.fit_transform(df[num_cols])

# ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±°
df.drop(columns=['ID', 'Label'], inplace=True)

# --------------------
# 6) íŠ¹ì§•(ë…ë¦½ë³€ìˆ˜)/íƒ€ê¹ƒ(ì¢…ì†ë³€ìˆ˜) ë¶„ë¦¬ ë° ë¶„í• 
# --------------------
X = df.drop('Label_enc', axis=1)
y = df['Label_enc']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# --------------------
# 7) í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
#    â†’ RandomizedSearchCV ì„ íƒ ì´ìœ :
#    - íƒìƒ‰ ê³µê°„ì´ í¬ê±°ë‚˜ ì‹œê°„ ì œì•½ì´ ìˆì„ ë•Œ íš¨ìœ¨ì 
# --------------------
param_dist = {
    'n_estimators': [50, 100, 200, 300],
    'max_depth': [None, 5, 10, 20],
    'max_features': ['auto', 'sqrt', 'log2'],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

base_clf = RandomForestClassifier(random_state=42)
rand_search = RandomizedSearchCV(
    estimator=base_clf,
    param_distributions=param_dist,
    n_iter=20,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)
rand_search.fit(X_train, y_train)
best_clf = rand_search.best_estimator_

# --------------------
# 8) í‰ê°€
# --------------------
# 8) í‰ê°€ (ìˆ˜ì •ëœ ë¶€ë¶„)
y_pred = best_clf.predict(X_test)

# 8-1) ì •í™•ë„
acc = accuracy_score(y_test, y_pred)
st.subheader('Model Performance')
st.write(f'**Accuracy:** {acc:.2f}')

# 8-2) Classification Report â†’ DataFrame â†’ Table
report_dict = classification_report(
    y_test, y_pred,
    target_names=le.classes_,
    output_dict=True
)
report_df = pd.DataFrame(report_dict).T.round(2)
st.subheader('Classification Report')
st.table(report_df)

# 8-3) Confusion Matrix
conf_mat = confusion_matrix(y_test, y_pred)
fig, ax = plt.subplots(figsize=(6, 5))
sns.heatmap(
    conf_mat, annot=True, fmt='d', cmap='YlGnBu',
    xticklabels=le.classes_, yticklabels=le.classes_, ax=ax
)
ax.set_xlabel('Predicted')
ax.set_ylabel('Actual')
ax.set_title('Confusion Matrix')
st.pyplot(fig)
